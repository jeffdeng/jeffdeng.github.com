---
layout: post
title:  "大流量高并发的解决方案之读"
date:   2015-10-29 12:00:00
categories:  🐘php

---

* content
{:toc}

###序
高并发的问题经常是面试中经常问到的问题。也经常成为面试官为难没有此方面开发经验同学的压轴问。我就在这里简单说下基本思路，其实基本思路简单，难的部分是细节实践和规模大的时候。

高并发分为2个部分，一个部分是读，一个部分是写，2个部分分开讲。这篇讲读的问题。

###什么是读高的并发问题
当一个网站流量大了的时候，比如微博，12306同时访问的人太多，会导致页面刷不出来，卡的要死，用户体验弱到爆。这些页面要是静态的还好，但是基本这些都是动态的，处理起来就非常麻烦了。

###高并发写瓶颈在哪里

>1. 带宽不够用了
>2. IO不够了，硬盘再快也快不下去了
>3. 数据库压力大了，顶不住这么频繁的查询
>4. 服务器处理请求到了假死状态，502 Bad Gate way
>5. 图片下载慢，静态资源加载时间长
>6. 其他...

###通用的解决方案模型
硬件不够的都可以通过加硬件搞定，甚至软件写的不好，也可以加机器搞定，还有用CDN加速。

那么在机器数量一定的情况下，用分布式的加机器，把读的压力分发出去，然后数据库再搞个主从，主数据库做写，从数据库做读，这样好了，数据库压力也减轻了。这样还不行，数据库压力还是大，访问速度不行，那就上终极杀招：缓存。

把重要的数据存放到内存缓存，对查询函数做个封装，取的时候先取缓存，缓存取不到再去msyql数据库查询。同时，写入新数据到主库的时候，用mysql的name_deinit(）触发一个任务，
任务异步更新到缓存，可以做触发更新，也可以是其他方式。
```
    //异步做这个，可以用gearman做worker,Supervisor设置gearman为驻守进程
    $redis = new Redis();
    $redis->connect('127.0.0.1', 6379);
    $redis->set($id, $msyqlRecordString);
```

因为缓存有个最大的问题：有一定延时性，导致和数据库不一致。更新策略关系着缓存好用不好用。

缓存现在用的最多是redis，做主从很方便配置，而memcache这种靠client做分布式的太不可靠了，而其它的开发者都已经放弃它了就不要用这么落后的东西了。

这些东西说起来就那么一套模型，具体实施起来却是个大工程。

有空再做个简单的示意图上传上来。





